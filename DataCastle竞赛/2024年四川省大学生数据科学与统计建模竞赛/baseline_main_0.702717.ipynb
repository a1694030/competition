{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据\n",
    "# 训练集\n",
    "train_df = pd.read_csv(\"./data/2024年四川省大学生数据科学与统计建模竞赛/训练集/train_data.csv\")\n",
    "target_df = pd.read_csv(\"./data/2024年四川省大学生数据科学与统计建模竞赛/训练集/train_target.csv\")\n",
    "# 合并\n",
    "train_df = train_df.merge(target_df,how='left',on='idx')\n",
    "# 测试集\n",
    "test_df = pd.read_csv(\"./data/2024年四川省大学生数据科学与统计建模竞赛/测试集/test_data.csv\")\n",
    "# 合并训练集，测试集\n",
    "train_df['is_test'] = 0\n",
    "test_df['is_test'] = 1\n",
    "df_all = pd.concat([train_df,test_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_num: 3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86130\\AppData\\Local\\Temp\\ipykernel_24320\\3866116383.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['date'] = test_df['date'].fillna(7.0)\n"
     ]
    }
   ],
   "source": [
    "# 删除缺失率>0.95\n",
    "drop_feats = ['X160', 'X294', 'X410', 'X629', 'X630', 'X631', 'X637', 'X645', 'X646', 'X653', 'X661', 'X662', 'X663', 'X664', 'X665', 'X666', 'X667', 'X668', 'X685', 'X686', 'X687', 'X688', 'X689', \n",
    "              'X690', 'X691', 'X692', 'X693', 'X694', 'X695', 'X696', 'X697', 'X698', 'X699', 'X700', 'X717', 'X718', 'X719', 'X720', 'X725', 'X726', 'X727', 'X728', 'X729', 'X730', 'X731', 'X732', \n",
    "              'X733', 'X734', 'X735', 'X736', 'X737', 'X765', 'X766', 'X767', 'X773', 'X781', 'X782', 'X789', 'X797', 'X798', 'X799', 'X800', 'X801', 'X802', 'X803', 'X804', 'X821', 'X822', 'X823', \n",
    "              'X824', 'X825', 'X826', 'X827', 'X828', 'X829', 'X830', 'X831', 'X832', 'X833', 'X834', 'X835', 'X836', 'X853', 'X854', 'X855', 'X856', 'X861', 'X862', 'X863', 'X864', 'X865', 'X866', \n",
    "              'X867', 'X868', 'X869', 'X870', 'X871', 'X872', 'X873', 'X957', 'X1176', 'X1177', 'X1178', 'X1184', 'X1192', 'X1193', 'X1200', 'X1208', 'X1209', 'X1210', 'X1211', 'X1212', 'X1213', \n",
    "              'X1214', 'X1215', 'X1232', 'X1233', 'X1234', 'X1235', 'X1236', 'X1237', 'X1238', 'X1239', 'X1240', 'X1241', 'X1242', 'X1243', 'X1244', 'X1245', 'X1246', 'X1247', 'X1264', 'X1265', \n",
    "              'X1266', 'X1267', 'X1272', 'X1273', 'X1274', 'X1275', 'X1276', 'X1277', 'X1278', 'X1279', 'X1280', 'X1281', 'X1282', 'X1283', 'X1284', 'X1453', 'X1454', 'X1455', 'X1458', 'X1459',\n",
    "              'X1467', 'X1524', 'X1525', 'X1723', 'X1911', 'X1928', 'X1958', 'X1985', 'X1987', 'X2060', 'X2061', 'X2090', 'X2094', 'X2095', 'X2096', 'X2104', 'X2106', 'X2108', 'X2109', 'X2123', \n",
    "              'X2124', 'X2125', 'X2126', 'X2127', 'X2129', 'X2130', 'X2131', 'X2132', 'X2133', 'X2134', 'X2135', 'X2136', 'X2146', 'X2147', 'X2148', 'X2167', 'X2168', 'X2176', 'X2177', 'X2178', \n",
    "              'X2179', 'X2200', 'X2201', 'X2202', 'X2203', 'X2204', 'X2205', 'X2206', 'X2207', 'X2222', 'X2224', 'X2225', 'X2233', 'X2236', 'X2238', 'X2241', 'X2247', 'X2249', 'X2255', 'X2259', \n",
    "              'X2262', 'X2263', 'X2276', 'X2355', 'X2395', 'X2403', 'X2425', 'X2426', 'X2427', 'X2432', 'X2434', 'X2436', 'X2440', 'X2444', 'X2446', 'X2447', 'X2448', 'X2450', 'X2457', 'X2458', \n",
    "              'X2467', 'X2469', 'X2470', 'X2471', 'X2472', 'X2473', 'X2475', 'X2476', 'X2477', 'X2478', 'X2479', 'X2482', 'X2483', 'X2492', 'X2493', 'X2497', 'X2511', 'X2513', 'X2514', 'X2515', \n",
    "              'X2516', 'X2517', 'X2519', 'X2520', 'X2521', 'X2522', 'X2524', 'X2525', 'X2526', 'X2527', 'X2528', 'X2529', 'X2530', 'X2531', 'X2533', 'X2535', 'X2536', 'X2545', 'X2624', 'X2625', \n",
    "              'X2626', 'X2627', 'X2628', 'X2629', 'X2630', 'X2631', 'X2632', 'X2633', 'X2634', 'X2635', 'X2636', 'X2637', 'X2638', 'X2639', 'X2640', 'X2641', 'X2642', 'X2643', 'X2644', 'X2645', \n",
    "              'X2646', 'X2647', 'X2648', 'X2649', 'X2650', 'X2651', 'X2652', 'X2653', 'X2654', 'X2655', 'X2656', 'X2657', 'X2658', 'X2659', 'X2674', 'X2675', 'X2678', 'X2679', 'X2680', 'X2681', \n",
    "              'X2684', 'X2781', 'X2782', 'X2783', 'X2784', 'X2965', 'X3288', 'X3289', 'X3290', 'X3291', 'X3292', 'X3293', 'X3294', 'X3295', 'X3476', 'X3477', 'X3478', 'X3538', 'X3558', 'X3559', \n",
    "              'X3560', 'X3578', 'X3579', 'X3580', 'X3581', 'X3582', 'X3583', 'X3584', 'X3585', 'X3586', 'X3587', 'X3588', 'X3589', 'X3590', 'X3591', 'X3592', 'X3593', 'X3594', 'X3595', 'X3596', \n",
    "              'X3597', 'X3598', 'X3599', 'X3600', 'X3601', 'X3602', 'X3603', 'X3604', 'X3605', 'X3606', 'X3607', 'X3608', 'X3609', 'X3610', 'X3611', 'X3612', 'X3613', 'X3614', 'X3615', 'X3616', \n",
    "              'X3617', 'X3618', 'X3619', 'X3620', 'X3621', 'X3622', 'X3623', 'X3624', 'X3625']\n",
    "\n",
    "# 分离训练集，测试集\n",
    "df_all = df_all.replace([-np.inf,np.inf],0)\n",
    "train_df = df_all[df_all['is_test']==0]\n",
    "test_df = df_all[df_all['is_test']==1]\n",
    "test_df['date'] = test_df['date'].fillna(7.0)\n",
    "\n",
    "# 对抗筛选\n",
    "adv_selected = ['X1993','X314','X155','X0','X312','X1990','X1992','X1989','X315','X1994']\n",
    "\n",
    "# 特征重要性\n",
    "# imp_tail5 = [ 'X2579', 'X49', 'X703', 'X87', 'X3716']\n",
    "\n",
    "# 方差筛选\n",
    "# var_threshold = df_all[feats].var().quantile(0.001)\n",
    "var_selected = ['X386','X933','X411''X958']  #[col for col in feats if df_all[col].var() < var_threshold]\n",
    "\n",
    "feats = [col for col in test_df if col not in ['idx','y','is_test']+drop_feats+adv_selected+var_selected]                                                                                                                                                                                      \n",
    "print('feats_num:',len(feats))\n",
    "\n",
    "# del df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Memory usage is: 1798.79 MB\n",
      "Memory usage after optimization is: 489.41 MB\n",
      "Decreased by 72.8%\n",
      "Start Memory usage is: 527.26 MB\n",
      "Memory usage after optimization is: 143.66 MB\n",
      "Decreased by 72.8%\n"
     ]
    }
   ],
   "source": [
    "# 内存压缩\n",
    "import time\n",
    "def reduce_mem_usage(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16','int32','int64','float16','float32 ','float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[ col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[ col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int' :\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8 ).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64 ).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype( np.float64)\n",
    "    end_mem = df.memory_usage( ).sum() / 1024**2\n",
    "    print('Start Memory usage is: {:.2f} MB'.format(start_mem))\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "reduce_mem_usage(train_df)\n",
    "reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 9999\n",
      "|  Model  Fold  1  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.698015\n",
      "[400]\tvalid_0's auc: 0.702122\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's auc: 0.702893\n",
      "Fold 1 score : 0.702892825047757\n",
      "***AVG_score :0.702892825047757 std :0.0***\n",
      "\n",
      "|  Model  Fold  2  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.684447\n",
      "[400]\tvalid_0's auc: 0.688035\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's auc: 0.688138\n",
      "Fold 2 score : 0.68813832202849\n",
      "***AVG_score :0.6955155735381235 std :0.007377251509633476***\n",
      "\n",
      "|  Model  Fold  3  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.685231\n",
      "[400]\tvalid_0's auc: 0.688523\n",
      "Early stopping, best iteration is:\n",
      "[457]\tvalid_0's auc: 0.690045\n",
      "Fold 3 score : 0.6900447664788034\n",
      "***AVG_score :0.6936919711850168 std :0.006552374453237451***\n",
      "\n",
      "|  Model  Fold  4  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.678152\n",
      "[400]\tvalid_0's auc: 0.680097\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's auc: 0.680937\n",
      "Fold 4 score : 0.6809366435128374\n",
      "***AVG_score :0.690503139266972 std :0.007918721818336824***\n",
      "\n",
      "|  Model  Fold  5  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's auc: 0.677999\n",
      "[400]\tvalid_0's auc: 0.679586\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's auc: 0.680876\n",
      "Fold 5 score : 0.6808758346397581\n",
      "***AVG_score :0.6885776783415293 std :0.008061918090044744***\n",
      "\n",
      "oof:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90     50526\n",
      "         1.0       0.65      0.04      0.07     11340\n",
      "\n",
      "    accuracy                           0.82     61866\n",
      "   macro avg       0.74      0.52      0.48     61866\n",
      "weighted avg       0.79      0.82      0.75     61866\n",
      "\n",
      "oof_score: 0.687873351879672\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "import gc\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight as cse\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report,f1_score,precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 自定义评估函数\n",
    "def my_metrice(preds, eval_data):\n",
    "    label = eval_data.get_label()\n",
    "    preds = np.argmax(preds.reshape(3,-1), axis=0)\n",
    "    prc = precision_score(label, preds, average='macro')\n",
    "    rec = recall_score(label, preds, average='macro')\n",
    "    score = (0.7*prc + 0.3*rec)*100\n",
    "    return ('score', score, True) \n",
    "    \n",
    "def lgb_model(train_x, train_y, test_x):\n",
    "    seeds=[2024]\n",
    "    oof = np.zeros([train_x.shape[0],])\n",
    "    test_predict = np.zeros([test_x.shape[0],])\n",
    "    feat_imp_df = pd.DataFrame()\n",
    "    feat_imp_df['feature'] = train_x.columns\n",
    "    feat_imp_df['imp'] = 0\n",
    "    for seed in seeds:\n",
    "        print('Seed:',seed)\n",
    "        folds = 5\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        scores = []\n",
    "        train_x =train_x.values\n",
    "        train_y = train_y.values\n",
    "\n",
    "        #五折交叉验证\n",
    "        for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "            print(\"|  Model  Fold  {}  Training Start           |\".format(str(i + 1)))         \n",
    "            trn_x, trn_y, val_x, val_y = train_x[train_index], train_y[train_index],\\\n",
    "                                         train_x[valid_index], train_y[valid_index] \n",
    "            # 模型参数\n",
    "            params={\"boosting_type\": \"gbdt\",\"objective\": \"binary\",\"metric\": \"auc\",\n",
    "                    \"verbose\": -1,'learning_rate':0.02,'num_leaves':128,\n",
    "                    'feature_fraction':0.8,'bagging_fraction':0.8\n",
    "                    }#'max_bin':188,\n",
    "\n",
    "            dtrain = lgb.Dataset(trn_x, label=trn_y,categorical_feature=[])\n",
    "            dval = lgb.Dataset(val_x, label=val_y,categorical_feature=[])\n",
    "            \n",
    "            # 模型定义\n",
    "            model = lgb.train(params, dtrain, valid_sets=[dval], num_boost_round=20000,\n",
    "                              callbacks=[lgb.early_stopping(200), lgb.log_evaluation(200)],\n",
    "                              ) #feval=my_metrice\n",
    "            # 预测\n",
    "            val_pred  = model.predict(val_x,num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x,num_iteration=model.best_iteration)\n",
    "\n",
    "            # 特征重要性\n",
    "            feat_imp_df['imp'] += model.feature_importance(importance_type='gain') / folds/ len(seeds)\n",
    "            feat_imp_df = feat_imp_df.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "            feat_imp_df['rank'] = range(feat_imp_df.shape[0])\n",
    "\n",
    "            # 结果保存\n",
    "            oof[valid_index] = val_pred / len(seeds)\n",
    "            test_predict += test_pred / kf.n_splits / len(seeds)\n",
    "            \n",
    "            # 模型评估\n",
    "            # val_pred = np.argmax(val_pred,axis=1)\n",
    "            score = roc_auc_score(val_y,val_pred)\n",
    "            print('Fold {} score : {}'.format(i+1,score))\n",
    "            scores.append(score)\n",
    "            print(\"***AVG_score :{} std :{}***\".format(np.mean(scores),np.std(scores)))\n",
    "            print(                                                                    )\n",
    "        print('oof:',classification_report(train_y,np.where(oof>0.5,1,0)))\n",
    "        print('oof_score:',roc_auc_score(train_y,oof))\n",
    "\n",
    "        del trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "        \n",
    "    return oof, test_predict,feat_imp_df\n",
    "\n",
    "# 训练LGB模型\n",
    "lgb_oof, lgb_test, lgb_imp_df = lgb_model(train_df[feats], train_df['y'], test_df[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sava\n",
    "pd.DataFrame({'idx':test_df['idx'],'y_pred':lgb_test}).to_csv('result.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
