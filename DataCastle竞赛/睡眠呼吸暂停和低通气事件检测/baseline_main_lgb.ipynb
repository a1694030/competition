{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#读取数据\n",
    "train_df = np.load(\"./data/训练集/train_x.npy\")\n",
    "train_y = np.load(\"./data/训练集/train_y.npy\")\n",
    "# test_df = np.load(\"./data/测试集A/test_x_A.npy\")\n",
    "test_df = np.load(\"./data/测试集B/test_x_B.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37549, 305) (1887, 304)\n"
     ]
    }
   ],
   "source": [
    "#读取特征\n",
    "#统计性特征\n",
    "train_feat = pd.read_csv('./data/train_feat.csv')\n",
    "train_feat['label'] = train_y\n",
    "test_feat = pd.read_csv('./data/test_feat_B.csv')\n",
    "\n",
    "#hrv特征\n",
    "cao_train_feat = pd.read_excel('./cao/feature/feature_train.xlsx')\n",
    "cao_test_feat = pd.read_excel('./cao/feature/feature_test_hrv_128.xlsx')\n",
    "cao_train_feat.drop(columns='label',inplace=True)\n",
    "\n",
    "#列名重置\n",
    "cao_train_feat.columns = cao_train_feat.columns + '_cao'\n",
    "cao_test_feat.columns = cao_test_feat.columns + '_cao'\n",
    "\n",
    "print(train_feat.shape,test_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12741, 432), (1887, 432))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#样本平衡\n",
    "train_df = train_feat[train_feat.label==0][:5000]._append(train_feat[train_feat.label!=0]).reset_index(drop=True)\n",
    "train_y = train_df['label']\n",
    "train_df = train_df.drop(columns='label')\n",
    "test_df = test_feat.reset_index(drop=True)\n",
    "\n",
    "#合并特征\n",
    "train_df = pd.concat([train_df,cao_train_feat],axis=1)\n",
    "test_df = pd.concat([test_df,cao_test_feat],axis=1)\n",
    "\n",
    "train_df.shape,test_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对抗验证\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#分离训练集，测试集\n",
    "train_df['is_test'] = 0\n",
    "test_df['is_test'] = 1\n",
    "feat = [col for col in train_df if col not in ['label','is_test']]\n",
    "print('筛选前 feat_num:',len(feat))\n",
    "\n",
    "\n",
    "def Adversarial_val(train_df,test_df,feat_cols,lable):\n",
    "    #合并\n",
    "    df = pd.concat([train_df,test_df],axis=0,ignore_index=True)\n",
    "    df = shuffle(df,random_state=16)\n",
    "    # model = lgb.LGBMClassifier(metric='auc',verbose=-1).fit(df[feat_cols],df[lable])\n",
    "    model = xgb.XGBClassifier(n_estimators=100,eval_metric= 'auc').fit(df[feat_cols],df[lable])\n",
    "    #imp\n",
    "    feat_imp_df = pd.DataFrame({'feature':feat_cols,'imp':np.zeros(len(feat_cols))})\n",
    "    imp = model.feature_importances_\n",
    "    feat_imp_df['imp'] = imp\n",
    "    feat_imp_df = feat_imp_df.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "    feat_imp_df['rank'] = range(feat_imp_df.shape[0])\n",
    "    #预测\n",
    "    df_pre = model.predict_proba(df[feat_cols])[:,1]\n",
    "    auc_score = roc_auc_score(df['is_test'],df_pre)\n",
    "    # print('AUC:',auc_score)\n",
    "    return model,df_pre,feat_imp_df,auc_score\n",
    "\n",
    "#特征筛选\n",
    "select_feat = []\n",
    "drop_feat = []\n",
    "\n",
    "for feat in tqdm(feat):\n",
    "    adv_model,df_pre,feat_imp_df,auc_score=Adversarial_val(train_df,test_df,[feat],'is_test')\n",
    "    if auc_score<0.66:\n",
    "        select_feat.append(feat)\n",
    "    else:\n",
    "        drop_feat.append(feat)\n",
    "print('筛选后 feat_num:',len(select_feat))\n",
    "feat_cols = select_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对抗验证筛选\n",
    "drop_feat = ['bo_mean', 'hr_mean', 'bo_shift_1_mean', 'hr_shift_1_mean', 'bo_shift_5_mean','hr_shift_5_mean', 'bo_shift_10_mean', 'hr_shift_10_mean', 'bo_shift_15_mean', \n",
    "  'hr_shift_15_mean', 'bo_shift_20_mean', 'hr_shift_20_mean', 'bo_shift_30_mean', 'bo_win10_mean_mean', 'hr_win10_mean_mean', 'hr_win10_std_mean', 'bo_hr_sub_mean', \n",
    "  'bo_hr_diff_mean', 'hr_win10_mean_max', 'bo_hr_sub_max', 'hr_win10_mean_min', 'bo_hr_sub_min','hr_std', 'hr_shift_1_std', 'hr_shift_5_std', 'hr_shift_10_std', 'hr_shift_15_std',\n",
    "  'hr_diff_15_std', 'bo_hr_sub_std', 'bo_win10_mean_median', 'hr_win10_mean_median', 'hr_win10_std_median', 'bo_hr_sub_median', 'hr_var', 'hr_shift_1_var', 'hr_shift_5_var',\n",
    "  'hr_shift_10_var', 'hr_shift_15_var', 'hr_diff_15_var', 'bo_hr_sub_var', 'bo_diff_1_kurt','bo_diff_5_kurt', 'hr_shift_15_kurt', 'cvsd_bo', 'mean_nni_hr', 'sdnn_hr', 'cvsd_hr', \n",
    "  'cvnni_hr', 'mean_hr_hr', 'std_hr_hr', 'mean_nni_hr_60_cao', 'sdnn_hr_60_cao', 'sdsd_hr_60_cao', 'rmssd_hr_60_cao', 'range_nni_hr_60_cao', 'cvnni_hr_60_cao', 'mean_hr_hr_60_cao', \n",
    "  'sdnn_index_hr_60_cao', 'hf_hr_60_cao', 'lf_hf_ratio_hr_60_cao', 'lfnu_hr_60_cao', 'hfnu_hr_60_cao', 'total_power_hr_60_cao', 'vlf_hr_60_cao', 'csi_hr_60_cao', 'cvi_hr_60_cao', \n",
    "  'Modified_csi_hr_60_cao', 'sd1_hr_60_cao', 'sd2_hr_60_cao', 'ratio_sd2_sd1_hr_60_cao', 'sampen_hr_60_cao', 'mean_nni_spo2_60_cao', 'mean_hr_spo2_60_cao', 'mean_nni_hr_180_cao', \n",
    "  'sdnn_hr_180_cao', 'cvnni_hr_180_cao', 'mean_hr_hr_180_cao', 'std_hr_hr_180_cao', 'sdnn_index_hr_180_cao', 'lf_hr_180_cao', 'hf_hr_180_cao', 'vlf_hr_180_cao', 'csi_hr_180_cao', \n",
    "  'Modified_csi_hr_180_cao', 'sd2_hr_180_cao', 'ratio_sd2_sd1_hr_180_cao', 'sampen_hr_180_cao', 'mean_nni_spo2_180_cao', 'mean_hr_spo2_180_cao']\n",
    "\n",
    "#人为筛选\n",
    "hr_drop_cols = ['mean_nni_hr', 'sdnn_hr', 'sdsd_hr', 'nni_50_hr', 'pnni_50_hr',\n",
    "       'nni_20_hr', 'pnni_20_hr', 'rmssd_hr', 'median_nni_hr', 'range_nni_hr',\n",
    "       'cvsd_hr', 'cvnni_hr', 'mean_hr_hr', 'max_hr_hr', 'min_hr_hr',\n",
    "       'std_hr_hr']\n",
    "rs_drop_cols = ['breathing_amplitude_hr_180_cao','breathing_frequency_hr_180_cao','snr_hr_180_cao','breathing_frequency_spo2_180_cao','breathing_amplitude_spo2_180_cao','snr_spo2_180_cao']#\n",
    "feat_cols =[col for col in train_df if col not in ['cvnni_bo', 'nni_50_hr', 'pnni_50_hr']+hr_drop_cols+drop_feat+rs_drop_cols]\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "len(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 2024\n",
      "|  Model  Fold  1  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 0.683096\tvalid_0's score: 0.696798\n",
      "0.696798493408663\n",
      "AVG_acc : 0.696798493408663\n",
      "std : 0.0\n",
      "|  Model  Fold  2  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 0.641321\tvalid_0's score: 0.72693\n",
      "0.7269303201506592\n",
      "AVG_acc : 0.7118644067796611\n",
      "std : 0.015065913370998107\n",
      "|  Model  Fold  3  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.610935\tvalid_0's score: 0.736347\n",
      "0.736346516007533\n",
      "AVG_acc : 0.7200251098556184\n",
      "std : 0.016867581723219578\n",
      "|  Model  Fold  4  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 0.630245\tvalid_0's score: 0.723164\n",
      "0.7231638418079096\n",
      "AVG_acc : 0.7208097928436912\n",
      "std : 0.014670844115708917\n",
      "|  Model  Fold  5  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.623805\tvalid_0's score: 0.743879\n",
      "0.743879472693032\n",
      "AVG_acc : 0.7254237288135593\n",
      "std : 0.01604183761886767\n",
      "|  Model  Fold  6  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.587161\tvalid_0's score: 0.73823\n",
      "0.7382297551789078\n",
      "AVG_acc : 0.7275580665411173\n",
      "std : 0.015402189763195588\n",
      "|  Model  Fold  7  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.612931\tvalid_0's score: 0.744821\n",
      "0.7448210922787194\n",
      "AVG_acc : 0.7300242130750606\n",
      "std : 0.015486416183859196\n",
      "|  Model  Fold  8  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's multi_logloss: 0.634562\tvalid_0's score: 0.721281\n",
      "0.7212806026365348\n",
      "AVG_acc : 0.7289312617702448\n",
      "std : 0.014772008946826516\n",
      "|  Model  Fold  9  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 0.635197\tvalid_0's score: 0.73258\n",
      "0.7325800376647834\n",
      "AVG_acc : 0.7293366813140825\n",
      "std : 0.01397431082407532\n",
      "|  Model  Fold  10  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 0.622868\tvalid_0's score: 0.720075\n",
      "0.7200754005655042\n",
      "AVG_acc : 0.7284105532392247\n",
      "std : 0.013545207477423167\n",
      "|  Model  Fold  11  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.612624\tvalid_0's score: 0.736098\n",
      "0.7360980207351555\n",
      "AVG_acc : 0.729109413920673\n",
      "std : 0.013102571377726453\n",
      "|  Model  Fold  12  Training Start           |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 0.634946\tvalid_0's score: 0.72196\n",
      "0.7219604147031102\n",
      "AVG_acc : 0.728513663985876\n",
      "std : 0.012699410477746484\n",
      "oof:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      5000\n",
      "           1       0.66      0.56      0.61      3221\n",
      "           2       0.67      0.70      0.68      4520\n",
      "\n",
      "    accuracy                           0.73     12741\n",
      "   macro avg       0.71      0.71      0.71     12741\n",
      "weighted avg       0.72      0.73      0.73     12741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report,f1_score,precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def my_metrice(preds, eval_data):\n",
    "    label = eval_data.get_label()\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    score = accuracy_score(label,preds)\n",
    "    return ('score', score, True) \n",
    "\n",
    "def lgb_model(train_x, train_y, test_x):\n",
    "    seeds=[2024]\n",
    "    oof = np.zeros([train_x.shape[0], 3])\n",
    "    test_predict = np.zeros([test_x.shape[0], 3])\n",
    "    feat_imp_df = pd.DataFrame()\n",
    "    feat_imp_df['feature'] = train_x.columns\n",
    "    feat_imp_df['imp'] = 0\n",
    "    for seed in seeds:\n",
    "        print('Seed:',seed)\n",
    "        folds = 12\n",
    "        kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        acc_scores = []\n",
    "        # train_x = train_x.values\n",
    "        # train_y = train_y.values\n",
    "        \n",
    "        for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "            print(\"|  Model  Fold  {}  Training Start           |\".format(str(i + 1)))\n",
    "            \n",
    "            trn_x, trn_y, val_x, val_y = train_x.values[train_index], train_y[train_index], train_x.values[valid_index], \\\n",
    "                                        train_y[valid_index] \n",
    "            \n",
    "            lgb_params={\"boosting_type\": \"gbdt\",\"objective\": \"multiclass\",\"metric\": \"multiclass\",\n",
    "                        'num_class':3,\"learning_rate\": 0.1,'verbose': -1,'num_leaves':36,\n",
    "                        }#'colsample_bytree':0.85,'subsample':0.85\n",
    "            dtrain = lgb.Dataset(trn_x, label=trn_y)\n",
    "            dval = lgb.Dataset(val_x, label=val_y)\n",
    "            lgb_model = lgb.train(lgb_params, dtrain, valid_sets=[dval], num_boost_round=20000,callbacks=[lgb.early_stopping(100), lgb.log_evaluation(500)],\n",
    "                                  feval=my_metrice)\n",
    "\n",
    "            val_pred  = lgb_model.predict(val_x,num_iteration=lgb_model.best_iteration)\n",
    "            test_pred = lgb_model.predict(test_x,num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "            #特征重要性\n",
    "            feat_imp_df['imp'] += lgb_model.feature_importance(importance_type='gain') / folds/ len(seeds)\n",
    "            feat_imp_df = feat_imp_df.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "            feat_imp_df['rank'] = range(feat_imp_df.shape[0])\n",
    "            \n",
    "            oof[valid_index] = val_pred/ len(seeds)\n",
    "            test_predict += test_pred / kf.n_splits / len(seeds)\n",
    "            \n",
    "            acc_score = accuracy_score(val_y,np.argmax(val_pred,axis=1))\n",
    "            print(acc_score)\n",
    "            acc_scores.append(acc_score)\n",
    "            print('AVG_acc :',sum(acc_scores)/len(acc_scores))\n",
    "            print('std :',np.std(acc_scores))\n",
    "        print('oof:',classification_report(train_y,np.argmax(oof,axis=1)))\n",
    "        \n",
    "    return oof, test_predict,feat_imp_df\n",
    "\n",
    "# 训练LGB模型\n",
    "lgb_oof, lgb_test, lgb_imp_df = lgb_model(train_df[feat_cols], train_y, test_df[feat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sub/B/submit_example_B.csv')\n",
    "submission['label'] = np.argmax(lgb_test,axis=1)\n",
    "# submission.to_csv('./sub/result.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jianyou_exercitation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
