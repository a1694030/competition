{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "LABEL = '装载量'\n",
    "\n",
    "df_train = pd.read_csv('./data/船舶装卸货量预测-训练集-20240611.csv', encoding='gbk')\n",
    "df_test = pd.read_csv('./data/船舶装卸货量预测-测试集X-20240611.csv', encoding='gbk')\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "df['离泊时间'] = df['离泊时间'].replace({' None': np.nan}).astype(float)\n",
    "df['time_diff'] = df['离泊时间'] - df['进泊时间']\n",
    "\n",
    "df['进泊时间'] = pd.to_datetime(df['进泊时间'], unit='s')\n",
    "df['离泊时间'] = pd.to_datetime(df['离泊时间'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2107, 72) (903, 72)\n"
     ]
    }
   ],
   "source": [
    "for f in ['进泊时间', '离泊时间']:\n",
    "    # df[f+'_year'] = df[f].dt.year\n",
    "    # df[f+'_month'] = df[f].dt.month\n",
    "    # df[f+'_day'] = df[f].dt.day\n",
    "    df[f+'_hour'] = df[f].dt.hour\n",
    "    df[f+'_dayofweek'] = df[f].dt.dayofweek\n",
    "    df[f+'_quarter'] = df[f].dt.quarter\n",
    "\n",
    "df['A_le'] = df['船舶类型代码A'].factorize()[0]\n",
    "df['B_le'] = df['船舶类型代码B'].factorize()[0]\n",
    "\n",
    "df['AB_le'] = (df['船舶类型代码A'] + '_' + df['船舶类型代码B']).factorize()[0]\n",
    "df['面积'] = df['船长'] * df['船宽']\n",
    "\n",
    "for num_f in ['载重吨', 'time_diff',]:\n",
    "    for cat_f in ['A_le', 'B_le','AB_le']:\n",
    "        df[cat_f + '_' + num_f + '_mean'] = df.groupby(cat_f)[num_f].transform('mean')\n",
    "        df[cat_f + '_' + num_f + '_std'] = df.groupby(cat_f)[num_f].transform('std')\n",
    "        df[cat_f + '_' + num_f + '_max'] = df.groupby(cat_f)[num_f].transform('max')\n",
    "        df[cat_f + '_' + num_f + '_min'] = df.groupby(cat_f)[num_f].transform('min')\n",
    "\n",
    "        \n",
    "        df[num_f + '_' + cat_f + '_mean'] = df.groupby(num_f)[cat_f].transform('mean')\n",
    "        df[num_f + '_' + cat_f  + '_std'] = df.groupby(num_f)[cat_f].transform('std')\n",
    "        df[num_f + '_' + cat_f  + '_max'] = df.groupby(num_f)[cat_f].transform('max')\n",
    "        df[num_f + '_' + cat_f + '_min'] = df.groupby(num_f)[cat_f].transform('min')\n",
    "\n",
    "\n",
    "\n",
    "df['loc0'] = df['泊位位置'].map(lambda x: float(x.split(' ')[0]))\n",
    "df['loc1'] = df['泊位位置'].map(lambda x: float(x.split(' ')[1]))\n",
    "\n",
    "# for f in ['载重吨','time_diff']:\n",
    "#     df['进泊_MDH_{}_medi'.format(f)] = df.groupby(['进泊时间_year','进泊时间_month','进泊时间_day'])[f].transform('median')\n",
    "    # df['进泊_MDH_{}_mean'.format(f)] = df.groupby(['进泊时间_year','进泊时间_month','进泊时间_day'])[f].transform('mean')\n",
    "#     df['进泊_MDH_{}_max'.format(f)] = df.groupby(['进泊时间_year','进泊时间_month','进泊时间_day'])[f].transform('max')\n",
    "\n",
    "\n",
    "df['船舶ID_航次ID_count'] = df.groupby('船舶ID')['航次ID'].transform('count')\n",
    "df['船舶ID_船舶类型代码A_count'] = df.groupby('船舶ID')['船舶类型代码A'].transform('count')\n",
    "df['船舶ID_船舶类型代码B_count'] = df.groupby('船舶ID')['船舶类型代码B'].transform('count')\n",
    "\n",
    "df['船舶ID_group_count'] = df['船舶ID'].map(df['船舶ID'].value_counts())\n",
    "df['船宽_group_count'] = df['船宽'].map(df['船宽'].value_counts())\n",
    "df['载重吨_group_count'] = df['载重吨'].map(df['载重吨'].value_counts())\n",
    "\n",
    "df['longitude/Latitude'] = df['loc0']/df['loc1']\n",
    "\n",
    "\n",
    "#替换穷值\n",
    "df = df.replace([-np.inf,np.inf],0)\n",
    "\n",
    "df_train = df[df[LABEL].notna()]\n",
    "df_test = df[df[LABEL].isna()]\n",
    "\n",
    "feats = [f for f in df_test if f not in [LABEL, '航次ID', '船舶类型代码A', '船舶类型代码B', '泊位位置','进泊时间', '离泊时间' ,'进泊时间_year','离泊时间_year']]\n",
    "\n",
    "print(df_train[feats].shape, df_test[feats].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 19422.6\n",
      "----------- 1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's rmse: 25189.8\n",
      "----------- 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's rmse: 20575.4\n",
      "----------- 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's rmse: 21410.9\n",
      "----------- 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's rmse: 18828.3\n",
      "----------- 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's rmse: 19557.6\n",
      "----------- 6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[412]\tvalid_0's rmse: 21120.5\n",
      "----------- 7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's rmse: 18728.1\n",
      "----------- 8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's rmse: 14123.1\n",
      "----------- 9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's rmse: 17480.4\n",
      "train_result 19834.13062210733\n"
     ]
    }
   ],
   "source": [
    "#lgb\n",
    "def lgb_train():\n",
    "    params_lgb = {'learning_rate': 0.03,'boosting_type': 'gbdt','objective': 'rmse','metric': 'rmse',\n",
    "                  'num_leaves': 32,'verbose': -1,'seed': 2222,'n_jobs': -1,'feature_fraction': 0.8,\n",
    "                  'bagging_fraction': 0.8,'bagging_freq': 4}\n",
    "    fold_num = 10\n",
    "    seeds = [22222]\n",
    "    lgb_oof = np.zeros(len(df_train))\n",
    "    importance = 0\n",
    "    pred_y = pd.DataFrame()\n",
    "\n",
    "    for seed in seeds:\n",
    "        # kf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "        kf = KFold(n_splits=fold_num, shuffle=False)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(df_train[feats], df_train[LABEL])):\n",
    "            print('-----------', fold)\n",
    "            train = lgb.Dataset(df_train.loc[train_idx, feats],\n",
    "                                (df_train.loc[train_idx, LABEL]))\n",
    "            val = lgb.Dataset(df_train.loc[val_idx, feats],\n",
    "                            (df_train.loc[val_idx, LABEL]))\n",
    "            model = lgb.train(params_lgb, train, valid_sets=[val], num_boost_round=20000,\n",
    "                            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(1000)])\n",
    "\n",
    "            lgb_oof[val_idx] += model.predict(df_train.loc[val_idx, feats]) / len(seeds)\n",
    "            pred_y['fold_%d_seed_%d' % (fold, seed)] = model.predict(df_test[feats])\n",
    "            importance += model.feature_importance(importance_type='gain') / fold_num\n",
    "    #result        \n",
    "    df_train['lgb_oof'] = lgb_oof\n",
    "    score = mse(df_train[LABEL], df_train['lgb_oof'], squared=False)\n",
    "    print('train_result',score)\n",
    "    feats_importance = pd.DataFrame()\n",
    "    feats_importance['name'] = feats\n",
    "    feats_importance['importance'] = importance\n",
    "    feats_importance.sort_values('importance', ascending=False)[:30]\n",
    "\n",
    "    return lgb_oof,pred_y.mean(axis=1).values,feats_importance\n",
    "\n",
    "lgb_oof,lgb_pre,lgb_imp = lgb_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 0\n",
      "[0]\ttrain-rmse:52840.89103\teval-rmse:46838.40100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[229]\ttrain-rmse:9045.06598\teval-rmse:17790.06501\n",
      "----------- 1\n",
      "[0]\ttrain-rmse:52007.68892\teval-rmse:54903.05306\n",
      "[257]\ttrain-rmse:8273.89844\teval-rmse:20362.02563\n",
      "----------- 2\n",
      "[0]\ttrain-rmse:52828.90204\teval-rmse:46831.35470\n",
      "[178]\ttrain-rmse:10211.11529\teval-rmse:19277.89645\n",
      "----------- 3\n",
      "[0]\ttrain-rmse:51980.61709\teval-rmse:54659.29287\n",
      "[329]\ttrain-rmse:7103.23131\teval-rmse:19357.74870\n",
      "----------- 4\n",
      "[0]\ttrain-rmse:52535.40889\teval-rmse:49435.10756\n",
      "[422]\ttrain-rmse:5828.52569\teval-rmse:14705.14265\n",
      "----------- 5\n",
      "[0]\ttrain-rmse:52187.97902\teval-rmse:52598.36257\n",
      "[182]\ttrain-rmse:9827.82907\teval-rmse:23463.67122\n",
      "----------- 6\n",
      "[0]\ttrain-rmse:51860.53083\teval-rmse:56259.81905\n",
      "[316]\ttrain-rmse:7515.73780\teval-rmse:20845.69843\n",
      "----------- 7\n",
      "[0]\ttrain-rmse:52111.73201\teval-rmse:53415.59745\n",
      "[316]\ttrain-rmse:7193.65745\teval-rmse:19824.68637\n",
      "----------- 8\n",
      "[0]\ttrain-rmse:52310.86945\teval-rmse:51460.36641\n",
      "[356]\ttrain-rmse:6732.96587\teval-rmse:19487.80900\n",
      "----------- 9\n",
      "[0]\ttrain-rmse:51914.35142\teval-rmse:55812.49405\n",
      "[232]\ttrain-rmse:8496.27009\teval-rmse:22407.09891\n",
      "train_result 19613.036443620036\n"
     ]
    }
   ],
   "source": [
    "#xgb\n",
    "def xgb_train():\n",
    "    params_xgb = {'booster': 'gbtree','eval_metric': 'rmse','min_child_weight': 5,'max_depth': 8,\n",
    "                  'subsample': 0.5,'colsample_bytree': 0.5,'eta': 0.03,'seed': 2222,'nthread': 36,\n",
    "                  'silent': True}\n",
    "    fold_num = 10\n",
    "    seeds = [22222]\n",
    "    xgb_oof = np.zeros(len(df_train))\n",
    "    # importance = 0\n",
    "    pred_y = pd.DataFrame()\n",
    "\n",
    "    for seed in seeds:\n",
    "        # kf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "        kf = KFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(df_train[feats], df_train[LABEL])):\n",
    "            print('-----------', fold)\n",
    "\n",
    "            \n",
    "            train = xgb.DMatrix(df_train.loc[train_idx, feats] , label=df_train.loc[train_idx, LABEL], missing=np.nan)\n",
    "            val = xgb.DMatrix(df_train.loc[val_idx, feats] , label=df_train.loc[val_idx, LABEL], missing=np.nan)\n",
    "            test  = xgb.DMatrix(df_test[feats], missing=np.nan)\n",
    "            watchlist = [(train, 'train'),(val, 'eval')]\n",
    "\n",
    "            model = xgb.train(params_xgb,train,num_boost_round=20000, evals=watchlist, verbose_eval=500,early_stopping_rounds=100)\n",
    "\n",
    "            xgb_oof[val_idx] += model.predict(val,iteration_range=(0, model.best_iteration)) / len(seeds)\n",
    "            pred_y['fold_%d_seed_%d' % (fold, seed)] = model.predict(test,iteration_range=(0, model.best_iteration))\n",
    "            # importance += model.feature_importance() / fold_num\n",
    "    #result        \n",
    "    df_train['xgb_oof'] = xgb_oof\n",
    "    score = mse(df_train[LABEL], df_train['xgb_oof'], squared=False)\n",
    "    print('train_result',score)\n",
    "    # feats_importance = pd.DataFrame()\n",
    "    # feats_importance['name'] = feats\n",
    "    # feats_importance['importance'] = importance\n",
    "    # feats_importance.sort_values('importance', ascending=False)[:30]\n",
    "    \n",
    "    return xgb_oof,pred_y.mean(axis=1).values\n",
    "\n",
    "xgb_oof,xgb_pre = xgb_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均加权： 19426.332430943\n"
     ]
    }
   ],
   "source": [
    "#平均融合\n",
    "score = mse(df_train[LABEL], (df_train['xgb_oof']+df_train['lgb_oof'])/2, squared=False)\n",
    "print('平均加权：',score)\n",
    "df_train['oof'] = (df_train['xgb_oof']+df_train['lgb_oof'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14279.37449446108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对装载量较大的船舶进行独立训练\n",
    "top_50_id = list(set(df_train.sort_values(by=['装载量','船舶ID',],ascending=False)[:50]['船舶ID']))\n",
    "df_train_copy = df_train.copy()\n",
    "lgb_model = lgb.LGBMRegressor(verbose=-1,n_estimators=1200,learning_rate=0.18).fit(df_train_copy.loc[df_train_copy['船舶ID'].isin(top_50_id),feats],df_train_copy.loc[df_train_copy['船舶ID'].isin(top_50_id),'装载量'])\n",
    "pre1 = lgb_model.predict(df_train_copy.loc[df_train_copy['船舶ID'].isin(top_50_id),feats])\n",
    "df_train.loc[df_train['船舶ID'].isin(top_50_id),'oof'] = pre1\n",
    "mse(df_train[LABEL], df_train['oof'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对异常LABEL进行后处理\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "outlier_df = df_train[['载重吨','装载量','oof']].copy()\n",
    "outlier_index = outlier_df.loc[outlier_df['载重吨']<outlier_df['oof']].index\n",
    "scores = []; Weights = []\n",
    "best_m = 0\n",
    "best_rmse=np.inf\n",
    "for m in np.arange(0.1,0.9,0.01):\n",
    "    df_train.loc[outlier_index,'oof'] = outlier_df.loc[outlier_df['载重吨']<outlier_df['oof'],'载重吨']*m\n",
    "    rmse_score = mse(df_train[LABEL], df_train['oof'], squared=False)\n",
    "    scores.append(rmse_score)\n",
    "    Weights.append(m)\n",
    "    if rmse_score < best_rmse:\n",
    "        best_rmse = rmse_score\n",
    "        best_m = m\n",
    "#替换\n",
    "df_train.loc[outlier_index,'oof'] = outlier_df.loc[outlier_df['载重吨']<outlier_df['oof'],'载重吨']*best_m\n",
    "# PLOT\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Weights,scores,'-o',color='blue')\n",
    "plt.scatter([best_m], [best_rmse], color='blue', s=300, alpha=1)\n",
    "plt.xlabel('Threshold',size=14)\n",
    "plt.ylabel('Validation F1 Score',size=14)\n",
    "plt.title(f'Weights vs. rmse with Best score = {best_rmse:.3f} at Best Threshold = {best_m:.3}',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对gap较大船舶进行后处理\n",
    "rmse_list = []\n",
    "for i in range(len(df_train)):\n",
    "    score_i = mse([df_train.loc[i,LABEL]], [df_train.loc[i,'oof']], squared=False)\n",
    "    rmse_list.append(score_i)\n",
    "\n",
    "rmse_df = pd.DataFrame({'rmse':rmse_list})\n",
    "\n",
    "df_train_copy = df_train.copy()\n",
    "gap_id = list(set(df_train.loc[rmse_df.sort_values(by='rmse',ascending=False)[:160].index]['船舶ID']))\n",
    "\n",
    "scores = []; Weights = []\n",
    "best_m3 = 0\n",
    "best_rmse3=np.inf\n",
    "for m in np.arange(0.8,1.2,0.01):\n",
    "    df_train.loc[df_train['船舶ID'].isin(gap_id),'oof'] =df_train_copy.loc[df_train_copy['船舶ID'].isin(gap_id),'oof']*m\n",
    "    rmse_score = mse(df_train[LABEL], df_train['oof'], squared=False)\n",
    "    scores.append(rmse_score)\n",
    "    Weights.append(m)\n",
    "    if rmse_score < best_rmse3:\n",
    "        best_rmse3 = rmse_score\n",
    "        best_m3 = m\n",
    "\n",
    "#替换\n",
    "df_train.loc[df_train['船舶ID'].isin(gap_id),'oof'] =df_train_copy.loc[df_train_copy['船舶ID'].isin(gap_id),'oof']*best_m3\n",
    "\n",
    "# PLOT\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Weights,scores,'-o',color='blue')\n",
    "plt.scatter([best_m3], [best_rmse3], color='blue', s=300, alpha=1)\n",
    "plt.xlabel('Threshold',size=14)\n",
    "plt.ylabel('Validation F1 Score',size=14)\n",
    "plt.title(f'Weights vs. rmse with Best score = {best_rmse3:.3f} at Best Weights = {best_m3:.3}',size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[LABEL] = (xgb_pre+lgb_pre)/2\n",
    "#对装载量较大的船舶进行独立预测\n",
    "lgb_test_pre = lgb_model.predict(df_test.loc[df_test['船舶ID'].isin(top_50_id),feats])\n",
    "df_test.loc[df_test['船舶ID'].isin(top_50_id),LABEL] = lgb_test_pre\n",
    "# #对异常LABEL进行后处理\n",
    "df_test.loc[df_test['载重吨']<df_test[LABEL],LABEL] = df_test['载重吨']*best_m\n",
    "#对量级较大的船舶进行后处理\n",
    "Large_cap_id = list(set(list(df_train[df_train['装载量']>=38239.000000]['船舶ID'])))\n",
    "df_test.loc[df_test['船舶ID'].isin(Large_cap_id),LABEL] = df_test.loc[df_test['船舶ID'].isin(Large_cap_id),LABEL]*1.055\n",
    "#对gap较大的船舶进行后处理\n",
    "df_test.loc[df_test['船舶ID'].isin(gap_id),LABEL] =df_test.loc[df_test['船舶ID'].isin(gap_id),LABEL]*best_m3\n",
    "#保存\n",
    "df_test[LABEL].to_csv('./sub/lgb_'+time.strftime('%Y%m%d-%H%M%S')+'_%d.txt'%score, index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
