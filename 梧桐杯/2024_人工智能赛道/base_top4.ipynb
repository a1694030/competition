{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#读取数据\n",
    "train_df = pd.read_csv(\"../data_ai/toUser/train.csv\")\n",
    "# A\n",
    "# test_df = pd.read_csv(\"../data_ai/toUser/testA.csv\")\n",
    "# sub = pd.read_csv(\"../data_ai/toUser/submitA.csv\")\n",
    "# B\n",
    "test_df = pd.read_csv(\"../data_ai/testB.csv\")\n",
    "sub = pd.read_csv(\"../data_ai/toUser/submitA.csv\")\n",
    "\n",
    "#合并训练集，测试集\n",
    "train_df['is_test'] = 0\n",
    "test_df['is_test'] = 1\n",
    "df_all = pd.concat([train_df,test_df],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间特征\n",
    "def extract_date_features(data,date_col):\n",
    "    \n",
    "    data[date_col]      = pd.to_datetime(data[date_col])\n",
    "    \n",
    "    data['Year']             = data[date_col].dt.year\n",
    "    data['Month']            = data[date_col].dt.month\n",
    "    data['Day']              = data[date_col].dt.day\n",
    "    data['Weekday']          = data[date_col].dt.weekday\n",
    "    data['Day_of_year']      = data[date_col].dt.dayofyear\n",
    "    data['Week_of_year']     = data[date_col].dt.isocalendar().week.astype(int)\n",
    "    data['Quarter']          = data[date_col].dt.quarter\n",
    "    data['Is_month_start']   = data[date_col].dt.is_month_start.astype(int)\n",
    "    data['Is_month_end']     = data[date_col].dt.is_month_end.astype(int)\n",
    "    data['Is_quarter_start'] = data[date_col].dt.is_quarter_start.astype(int)\n",
    "    data['Is_quarter_end']   = data[date_col].dt.is_quarter_end.astype(int)\n",
    "    data['Is_year_start']    = data[date_col].dt.is_year_start.astype(int)\n",
    "    data['Is_year_end']      = data[date_col].dt.is_year_end.astype(int)\n",
    "    data['Days_in_month']    = data[date_col].dt.days_in_month.astype(int)\n",
    "    data['Is_leap_year']     = data[date_col].dt.is_leap_year.astype(int)\n",
    "    data['Is_weekend']       = data['Weekday'].apply(lambda x: x >= 5).astype(int)\n",
    "    data['Days_till_month_end']    = data['Days_in_month'] - data['Day']\n",
    "    data['Days_since_month_start'] = data['Day'] - 1\n",
    "    data['Week_of_month']          = (data['Day'] - 1) // 7 + 1\n",
    "    data['Weekday_of_month']       = (data['Day'] - 1) % 7 + 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "df_all = extract_date_features(df_all,'join_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#缺失比例大于50%的列,是否缺失二分类\n",
    "for col in ['sl_flag','sl_type']:\n",
    "    df_all[col] = np.where(df_all[col].isna(),1,0)\n",
    "   \n",
    "#缩放\n",
    "ll_clos = ['ztc_gprs_res','avg3_tc_ll','avg3_tw_ll','avg3_dou','avg3_sl_ll',\n",
    "           'sl_ll2','avg3_video_app_ll','avg3_music_app_ll','avg3_game_app_ll']\n",
    "for col in ll_clos:\n",
    "    df_all[col] = df_all[col]/1024\n",
    "    \n",
    "#编码\n",
    "df_all['zfk_type'] = df_all['zfk_type'].factorize()[0]\n",
    "df_all['jt_5gwl_flag'] = df_all['jt_5gwl_flag'].factorize()[0]\n",
    "df_all['term_brand'] = df_all['term_brand'].factorize()[0]\n",
    "df_all['area_code'] = df_all['area_code'].astype('str').factorize()[0]\n",
    "\n",
    "#替换异常值\n",
    "df_all['age'] = df_all['age'].replace(999,np.nan)\n",
    "df_all['term_brand'] = df_all['term_brand'].replace(-1,np.nan)\n",
    "\n",
    "# # #用户特征\n",
    "# #交叉统计特征\n",
    "#area_code(81.4856727064221)\n",
    "df_all['area_code_change_equip_period_avg_mean'] = df_all['area_code'].map(df_all.groupby('area_code')['change_equip_period_avg'].mean())\n",
    "df_all['area_code_term_price_mean'] = df_all['area_code'].map(df_all.groupby('area_code')['term_price'].mean())\n",
    "df_all['area_code_ztc_gprs_res_mean'] = df_all['area_code'].map(df_all.groupby('area_code')['ztc_gprs_res'].mean())\n",
    "# #age(81.67717928649066)\n",
    "df_all['age_change_equip_period_avg_mean'] = df_all['age'].map(df_all.groupby('age')['change_equip_period_avg'].mean())\n",
    "df_all['age_term_price_mean'] = df_all['age'].map(df_all.groupby('age')['term_price'].mean())\n",
    "df_all['age_ztc_gprs_res_mean'] = df_all['age'].map(df_all.groupby('age')['ztc_gprs_res'].mean())\n",
    "#user_type、group_type\n",
    "df_all['enc_feat1'] = (df_all['user_type'].astype('str') + '_' + df_all['group_type'].astype('str')).factorize()[0]\n",
    "#jt_5gzd_flag、jt_5gwl_flag\n",
    "df_all['enc_feat2'] = (df_all['jt_5gzd_flag'].astype('str') + '_' + df_all['jt_5gwl_flag'].astype('str')).factorize()[0]\n",
    "#term_brand\n",
    "df_all['term_brand_term_price_mean'] = df_all['term_brand'].map(df_all.groupby('term_brand')['term_price'].mean())\n",
    "df_all['term_brand_change_equip_period_avg_mean'] = df_all['term_brand'].map(df_all.groupby('term_brand')['change_equip_period_avg'].mean())\n",
    "df_all['term_brand_ztc_gprs_res_mean'] = df_all['term_brand'].map(df_all.groupby('term_brand')['ztc_gprs_res'].mean())\n",
    "df_all['term_brand_ztc_price_mean'] = df_all['term_brand'].map(df_all.groupby('term_brand')['ztc_price'].mean())\n",
    "                                                 \n",
    "# #套餐资费-内容洞察特征(81.5552985500075)\n",
    "# #组合特征\n",
    "#流量占比\n",
    "df_all['avg3_video_app_ll_sl_ll2_sub'] = df_all['avg3_video_app_ll']/df_all['sl_ll2']\n",
    "df_all['avg3_music_app_ll_sl_ll2_sub'] = df_all['avg3_music_app_ll']/df_all['sl_ll2']\n",
    "df_all['avg3_game_app_ll_sl_ll2_sub'] = df_all['avg3_game_app_ll']/df_all['sl_ll2']\n",
    "#流量费用占比\n",
    "df_all['avg3_tc_price_avg3_tot_fee_sub'] = df_all['avg3_tc_price']/df_all['avg3_tot_fee']\n",
    "df_all['avg3_ctll_fee_avg3_tot_fee_sub'] = df_all['avg3_ctll_fee']/df_all['avg3_tot_fee']\n",
    "df_all['avg3_ctyy_fee_avg3_tot_fee_sub'] = df_all['avg3_ctll_fee']/df_all['avg3_ctyy_fee']\n",
    "\n",
    "# #不同数字产品占比情况(81.58818559286505)\n",
    "df_all['video_app1_cnt_rate'] = df_all['avg3_video_app1_cnt']/df_all[['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']].sum(axis=1)\n",
    "df_all['video_app2_cnt_rate'] = df_all['avg3_video_app2_cnt']/df_all[['avg3_video_app2_cnt','avg3_music_app2_cnt','avg3_game_app2_cnt']].sum(axis=1)\n",
    "df_all['video_app_ll_rate'] = df_all['avg3_video_app_ll']/df_all[['avg3_video_app_ll','avg3_music_app_ll','avg3_game_app_ll']].sum(axis=1)\n",
    "\n",
    "df_all['music_app1_cnt_rate'] = df_all['avg3_music_app1_cnt']/df_all[['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']].sum(axis=1)\n",
    "df_all['music_app2_cnt_rate'] = df_all['avg3_music_app2_cnt']/df_all[['avg3_video_app2_cnt','avg3_music_app2_cnt','avg3_game_app2_cnt']].sum(axis=1)\n",
    "df_all['music_app_ll_rate'] = df_all['avg3_music_app_ll']/df_all[['avg3_video_app_ll','avg3_music_app_ll','avg3_game_app_ll']].sum(axis=1)\n",
    "\n",
    "df_all['game_app1_cnt_rate'] = df_all['avg3_game_app1_cnt']/df_all[['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']].sum(axis=1)\n",
    "df_all['game_app2_cnt_rate'] = df_all['avg3_game_app2_cnt']/df_all[['avg3_video_app2_cnt','avg3_music_app2_cnt','avg3_game_app2_cnt']].sum(axis=1)\n",
    "df_all['game_app_ll_rate'] = df_all['avg3_game_app_ll']/df_all[['avg3_video_app_ll','avg3_music_app_ll','avg3_game_app_ll']].sum(axis=1)\n",
    "#数字产品使用情况\n",
    "df_all['app1_cnt_sum'] = df_all[['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']].sum(axis=1)\n",
    "df_all['app1_cnt_mean'] = df_all[['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']].mean(axis=1)\n",
    "df_all['app2_cnt_mean'] = df_all[['avg3_video_app2_cnt','avg3_music_app2_cnt','avg3_game_app2_cnt']].mean(axis=1)\n",
    "df_all['app_ll_mean'] = df_all[['avg3_video_app2_cnt','avg3_music_app_ll','avg3_game_app_ll']].mean(axis=1)\n",
    "\n",
    "#交叉统计特征(81.62299066727917)\n",
    "#APP使用个数\n",
    "for col_i in ['area_code','age']:\n",
    "    for col_j in ['avg3_video_app1_cnt','avg3_music_app1_cnt','avg3_game_app1_cnt']:\n",
    "        df_all[f'{col_i}_{col_j}_mean'] = df_all[col_i].map(df_all.groupby(col_i)[col_j].mean())\n",
    "    \n",
    "#APP使用天次数\n",
    "for col_i in ['area_code','age',]:\n",
    "    for col_j in ['avg3_video_app2_cnt','avg3_music_app2_cnt','avg3_game_app2_cnt']:\n",
    "        df_all[f'{col_i}_{col_j}_mean'] = df_all[col_i].map(df_all.groupby(col_i)[col_j].mean())\n",
    "    \n",
    "#APP使用总流量\n",
    "for col_i in ['area_code','age',]:\n",
    "    for col_j in ['avg3_video_app_ll','avg3_music_app_ll','avg3_game_app_ll']:\n",
    "        df_all[f'{col_i}_{col_j}_mean'] = df_all[col_i].map(df_all.groupby(col_i)[col_j].mean())\n",
    "        \n",
    "#业务使用\n",
    "#'avg3_dou','avg3_mou','avg3_llct_cnt','avg3_ll_bhd','avg3_sl_ll','avg3_tc_price','avg3_tot_fee','avg3_ctll_fee','avg3_ctyy_fee'\n",
    "for col_i in ['area_code','age',]:\n",
    "    for col_j in ['avg3_ll_bhd','avg3_tc_price','ll_bhd','avg3_dou','avg3_mou','avg3_llct_cnt',\n",
    "                  'avg3_ll_bhd','avg3_sl_ll','avg3_tc_price','avg3_tot_fee','avg3_ctll_fee','avg3_ctyy_fee']:\n",
    "        df_all[f'{col_i}_{col_j}_mean'] = df_all[col_i].map(df_all.groupby(col_i)[col_j].mean())\n",
    "\n",
    "df_all['avg3_tc_ll_avg3_tw_ll_sub'] = df_all['avg3_tc_ll']/df_all['avg3_tw_ll']\n",
    "df_all['avg3_tc_ll_avg3_tw_ll_sum'] = df_all['avg3_tc_ll']+df_all['avg3_tw_ll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除方差为0\n",
    "drops_cols = [col for col in df_all.drop(columns=['user_id','join_date']) if df_all[col].var()==0]\n",
    "\n",
    "#类别特征\n",
    "cat_cols = ['area_code','gender_id','zfk_type','group_type','jt_5gzd_flag','jt_5gwl_flag',\n",
    "            'avg3_llb_flag','avg3_llct_cnt','avg3_yyct_cnt']\n",
    "\n",
    "#分离训练集，测试集\n",
    "df_all = df_all.replace([-np.inf,np.inf],0)\n",
    "df_all = df_all.fillna(0)\n",
    "train_df = df_all[df_all['is_test']==0]\n",
    "test_df = df_all[df_all['is_test']==1]\n",
    "train_df['sample_flag'] = train_df['sample_flag']-1\n",
    "\n",
    "#重复值删除\n",
    "train_df = train_df.drop_duplicates(subset=[col for col in test_df if col not in ['user_id','join_date','sample_flag','is_test']],\n",
    "                                    keep='first', inplace=False).reset_index(drop=True)\n",
    "feats = [col for col in test_df if col not in ['user_id','join_date','sample_flag','is_test']+drops_cols]                                                                                                                                                                                      \n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#内存压缩\n",
    "import time\n",
    "def reduce_mem_usage(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16','int32','int64','float16','float32 ','float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[ col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[ col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int' :\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8 ).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64 ).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype( np.float64)\n",
    "    end_mem = df.memory_usage( ).sum() / 1024**2\n",
    "    print('Start Memory usage is: {:.2f} MB'.format(start_mem))\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "reduce_mem_usage(train_df)\n",
    "reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight as cse\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report,f1_score,precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 标准化\n",
    "def scale(train_features,test_features):\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(train_features)\n",
    "    train_features=pd.DataFrame(scaler.transform(train_features),columns=test_features.keys())\n",
    "    test_features=pd.DataFrame(scaler.transform(test_features),columns=test_features.keys())\n",
    "    return train_features.values,test_features.values\n",
    "\n",
    "# 自定义评估函数\n",
    "def my_metrice(preds, eval_data):\n",
    "    label = eval_data.get_label()\n",
    "    preds = np.argmax(preds.reshape(3,-1), axis=0)\n",
    "    prc = precision_score(label, preds, average='macro')\n",
    "    rec = recall_score(label, preds, average='macro')\n",
    "    score = (0.7*prc + 0.3*rec)*100\n",
    "    return ('score', score, True) \n",
    "\n",
    "# 评估函数\n",
    "def eva_func(true_labels,preds):\n",
    "    prc = precision_score(true_labels, preds, average='macro')\n",
    "    rec = recall_score(true_labels, preds, average='macro')\n",
    "    score = (0.7*prc + 0.3*rec)*100\n",
    "    return score\n",
    "    \n",
    "def lgb_model(train_x, train_y, test_x):\n",
    "    seeds=[9999]\n",
    "    oof = np.zeros([train_x.shape[0],3])\n",
    "    test_predict = np.zeros([test_x.shape[0],3])\n",
    "    feat_imp_df = pd.DataFrame()\n",
    "    feat_imp_df['feature'] = train_x.columns\n",
    "    feat_imp_df['imp'] = 0\n",
    "    for seed in seeds:\n",
    "        print('Seed:',seed)\n",
    "        folds = 5\n",
    "        kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "        scores = []\n",
    "        train_x =train_x.values\n",
    "        train_y = train_y.values\n",
    "        #5折交叉验证\n",
    "        for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "            print(\"|  Model  Fold  {}  Training Start           |\".format(str(i + 1)))         \n",
    "            trn_x, trn_y, val_x, val_y = train_x[train_index], train_y[train_index],\\\n",
    "                                         train_x[valid_index], train_y[valid_index] \n",
    "            # mdoel params\n",
    "            params={\"boosting_type\": \"gbdt\",\"objective\": \"multiclass\",\"metric\": [\"multi_error\"],\n",
    "                    'num_class':3,\"verbose\": -1,'learning_rate':0.02,'num_leaves':128,'max_bin':155,\n",
    "                    'feature_fraction':0.8,'bagging_fraction':0.8\n",
    "                     }\n",
    "\n",
    "            dtrain = lgb.Dataset(trn_x, label=trn_y,categorical_feature=[])\n",
    "            dval = lgb.Dataset(val_x, label=val_y,categorical_feature=[])\n",
    "            # 模型定义\n",
    "            model = lgb.train(params, dtrain, valid_sets=[dval], num_boost_round=20000,\n",
    "                              callbacks=[lgb.early_stopping(50), lgb.log_evaluation(10)],\n",
    "                              feval=my_metrice)\n",
    "            # predict\n",
    "            val_pred  = model.predict(val_x,num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x,num_iteration=model.best_iteration)\n",
    "            # feature_importance\n",
    "            feat_imp_df['imp'] += model.feature_importance(importance_type='gain') / folds/ len(seeds)\n",
    "            feat_imp_df = feat_imp_df.sort_values(by='imp', ascending=False).reset_index(drop=True)\n",
    "            feat_imp_df['rank'] = range(feat_imp_df.shape[0])\n",
    "            # save\n",
    "            oof[valid_index] = val_pred / len(seeds)\n",
    "            test_predict += test_pred / kf.n_splits / len(seeds)\n",
    "            \n",
    "            # 模型评估\n",
    "            val_pred = np.argmax(val_pred,axis=1)\n",
    "            score = eva_func(val_y,val_pred)\n",
    "            print('Fold {} score : {}'.format(i+1,score))\n",
    "            scores.append(score)\n",
    "            print(\"***AVG_score :{} std :{}***\".format(np.mean(scores),np.std(scores)))\n",
    "            print(                                                                    )\n",
    "        print('oof:',classification_report(train_y,np.argmax(oof,axis=1)))\n",
    "        print('oof_score:',eva_func(train_y,np.argmax(oof,axis=1)))\n",
    "        \n",
    "    return oof, test_predict,feat_imp_df\n",
    "\n",
    "# 训练LGB模型\n",
    "lgb_oof, lgb_test, lgb_imp_df = lgb_model(train_df[feats], train_df['sample_flag'], test_df[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提交\n",
    "sub['user_id'] = list(test_df['user_id'])\n",
    "sub['predtype'] = np.argmax(lgb_test,axis=1)+1\n",
    "sub.to_csv('result.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! castlecli --third honghu --token 66f8ee1c068eb479612599715244f9fa --source result.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
